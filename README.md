# サンプル（プロダクト名）

[![IMAGE ALT TEXT HERE](https://jphacks.com/wp-content/uploads/2024/07/JPHACKS2024_ogp.jpg)](https://www.youtube.com/watch?v=DZXUkEj-CSI)

## 製品概要
### 背景(製品開発のきっかけ、課題等）
視覚障害者の歩行を支援するアプリは既存にあるが、買いたい商品を買うことのできる支援アプリはない。スーパーにたどり着いたとしても解体商品がどこにあるかがわからない。
### 製品説明（具体的な製品の説明）
- 1.買いたい商品を音声で入力する。（複数商品入力することができる。）
- 2.買いたい商品を選択したら「確定」と話す。
- 3.動画撮影の画面へ遷移する。
- 4.買いたい商品が近くにあれば音声によって左側にりんごがあるといった支援を行い、商品へ近づける。
- 5.商品の前まで近づいたら、商品のポップから値段などの商品情報を音声で伝える。
- 6.かごに商品を入れたら、3本指で画面をタップする。
- 7.リストに購入したい商品が残っていれば手順の３に移動し、商品を探す。
### 特長
#### 1. 特長1
商品の位置まで誘導するだけでなく、商品の情報を音声で伝えられること
#### 2. 特長2
on deviceですべてネットワークとの通信をせずに行うことができるためセキュリティの問題に強い
#### 3. 特長3
自作モデル開発。画像の認識可能クラスを増やすためにfine-tuning

### 解決出来ること
視覚障害者が１人で買いたい商品が買うことができることや、その商品の情報が視覚障害者に伝えられ楽しく買い物をすることができる。
### 今後の展望
- 単眼深度推定により商品の位置も伝えるようにする。
- スーパーは大体野菜→生肉→お菓子→冷凍食品→飲料→お惣菜→パン類などある程度決まった場所に配置されているので、ある程度の予測モデルを用いた支援
- 毎日同じスーパーに通うのであれば日々のデータからどこに何があるかを学習し最適なルートで欲しい商品を手に入れられるようにする。
- クラス数に縛りがあるためfunetuningを行なって選択可能なクラス数を増やしていく。
- 「確定」の後、商品の追加をしたい時に商品を選択し直したくなった場合の戻る機能の追加。誤って３本タップした時の戻る機能など。
### 注力したこと（こだわり等）
* どのお店にも対応できるように画像認識を用いた。（既存に購入可能なデータセットを用意しておくのではなく）
* 全てon deviceで完結することから支援に対してどのような環境でも支援することが可能になる。
* 視覚障害者のため、音声での完結。３本指でタップするなどのアプリ起動からアプリ終了まで全て視覚情報を一切用いないこと。
* 

## 開発技術

- YOLOを用いた画像認識
- 購入したい商品の音声認識
- swift?
### 活用した技術
技術がここにくる？
CoreMLの画像認識技術
#### API・データ
* 食べ物の学習データ（画像）
* 

#### フレームワーク・ライブラリ・モジュール
* swift
* coreML
* YOLO

#### デバイス
* ios app
* 

### 独自技術
#### ハッカソンで開発した独自機能・技術
* 独自で開発したものの内容をこちらに記載してください
* 特に力を入れた部分をファイルリンク、またはcommit_idを記載してください。
